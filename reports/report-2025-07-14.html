<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Research Report - 2025-07-14</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 3px solid #007bff;
            padding-bottom: 10px;
        }
        .ai-summary {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #007bff;
        }
        .paper {
            border: 1px solid #ddd;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
            background: #fafafa;
        }
        .paper h3 {
            margin-top: 0;
            color: #007bff;
        }
        .paper a {
            color: #007bff;
            text-decoration: none;
        }
        .paper a:hover {
            text-decoration: underline;
        }
        .meta {
            color: #666;
            font-size: 14px;
            margin: 20px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🤖 AI Research Report</h1>
        <div class="meta">
            <strong>Date:</strong> 2025-07-14<br>
            <strong>Topics:</strong> large language models, artificial general intelligence, AI safety, robotics AI<br>
            <strong>Papers Found:</strong> 10
        </div>
        
        
        <div class="ai-summary">
            <h2>🤖 AI Summary</h2>
            <p>The research papers presented span a diverse array of topics within theoretical physics, AI interpretability, video generation, neural interfaces, and more. In "Infra-red enhanced loops in quadratic gravity," Salvio et al. explore the complex nature of quadratic gravity, challenging previous assumptions about asymptotic freedom by demonstrating that infra-red log-enhanced loop corrections are process-dependent and not absorbable into running couplings. This finding has significant implications for our understanding of gravity at quantum scales and highlights the necessity for more refined models that accurately capture these nuances.

In the realm of AI interpretability, Sutter et al. in "The Non-Linear Representation Dilemma" scrutinize the concept of causal abstraction in neural networks. They reveal that unrestricted causal abstraction, which allows for non-linear mappings between model representations and higher-level algorithms, ultimately dilutes its interpretative power. This paper raises critical questions about the balance between complexity and accuracy in AI interpretability, suggesting that causal abstraction alone may not suffice for mechanistic understanding without constraints on how models encode information.

Lumos-1, introduced by Yuan et al., represents a significant stride in autoregressive video generation by maintaining the large language model (LLM) architecture with minimal modifications, effectively addressing latency issues inherent in next-token decoding. The implementation of MM-RoPE and AR-DF techniques in Lumos-1 underscores the potential of leveraging LLMs for complex multimodal tasks, marking a pivotal step towards unified models capable of handling spatiotemporal data efficiently. Meanwhile, NeuralOS by Rivard et al. pushes the boundaries of neural generative models into simulating operating systems, highlighting advancements in creating adaptive interfaces that respond realistically to user interactions, though challenges remain in modeling fine-grained keyboard inputs.

In reinforcement learning, McCarthy et al.'s "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning" offers a novel exploration strategy that balances risk-aversion with reward optimization through an approach called Optimistic Risk-averse Actor Critic (ORAC). This method enhances exploration efficiency in uncertain environments, showing promise in continuous control tasks like Safety-Gymnasium. Additionally, Belitsky et al. introduce cache steering as an efficient method to induce reasoning capabilities in small language models, demonstrating its effectiveness in improving task performance without necessitating model fine-tuning.

Lastly, the paper "The Effective Field Theory of Large Scale Structure for Mixed Dark Matter Scenarios" by Verdiani et al. presents a theoretical framework to better understand cosmological fluctuations in mixed dark matter scenarios. This work extends previous models to accommodate non-cold dark matter components, providing new analytical solutions and refining constraints on dark matter properties, which could significantly influence future cosmological studies and our understanding of the universe's large-scale structure.

These contributions collectively underscore ongoing trends in AI and theoretical physics, such as the push for more interpretable AI models, the integration of LLMs into multimodal tasks, and refined cosmological modeling. They highlight the importance of balancing complexity with interpretability and accuracy, both in AI and in understanding fundamental physical phenomena.</p>
        </div>
    
        
        <h2>📚 Research Papers</h2>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08803v1" target="_blank">Infra-red enhanced loops in quadratic gravity</a></h3>
                <p><strong>Authors:</strong> Alberto Salvio, Alessandro Strumia, Marco Vitti</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> hep-th, gr-qc, hep-ph</p>
                <p><strong>Summary:</strong> It has been suggested that logarithmically enhanced infra-red loop corrections arising in theories with four derivatives correspond to a physical running of couplings, rendering quadratic gravity asymptotically free. We find that these effects depend on the gauge and on the field parameterisation. We compute physical on-shell amplitudes and find genuine infra-red log-enhanced loop corrections, that are process-dependent and cannot be absorbed into running couplings. As a byproduct, we derive the effective action of quadratic gravity at tree level, showing that its ghost does not contribute to effective operators and thereby does not violate positivity bounds.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08802v1" target="_blank">The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?</a></h3>
                <p><strong>Authors:</strong> Denis Sutter, Julian Minder, Thomas Hofmann, Tiago Pimentel</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.LG</p>
                <p><strong>Summary:</strong> The concept of causal abstraction got recently popularised to demystify the opaque decision-making processes of machine learning models; in short, a neural network can be abstracted as a higher-level algorithm if there exists a function which allows us to map between them. Notably, most interpretability papers implement these maps as linear functions, motivated by the linear representation hypothesis: the idea that features are encoded linearly in a model's representations. However, this linearity constraint is not required by the definition of causal abstraction. In this work, we critically examine the concept of causal abstraction by considering arbitrarily powerful alignment maps. In particular, we prove that under reasonable assumptions, any neural network can be mapped to any algorithm, rendering this unrestricted notion of causal abstraction trivial and uninformative. We complement these theoretical findings with empirical evidence, demonstrating that it is possible to perfectly map models to algorithms even when these models are incapable of solving the actual task; e.g., on an experiment using randomly initialised language models, our alignment maps reach 100% interchange-intervention accuracy on the indirect object identification task. This raises the non-linear representation dilemma: if we lift the linearity constraint imposed to alignment maps in causal abstraction analyses, we are left with no principled way to balance the inherent trade-off between these maps' complexity and accuracy. Together, these results suggest an answer to our title's question: causal abstraction is not enough for mechanistic interpretability, as it becomes vacuous without assumptions about how models encode information. Studying the connection between this information-encoding assumption and causal abstraction should lead to exciting future work.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08801v1" target="_blank">Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective</a></h3>
                <p><strong>Authors:</strong> Hangjie Yuan, Weihua Chen, Jun Cen, Hu Yu, Jingyun Liang, Shuning Chang, Zhihui Lin, Tao Feng, Pengwei Liu, Jiazheng Xing, Hao Luo, Jiasheng Tang, Fan Wang, Yi Yang</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.CV, cs.AI, cs.MM</p>
                <p><strong>Summary:</strong> Autoregressive large language models (LLMs) have unified a vast range of language tasks, inspiring preliminary efforts in autoregressive video generation. Existing autoregressive video generators either diverge from standard LLM architectures, depend on bulky external text encoders, or incur prohibitive latency due to next-token decoding. In this paper, we introduce Lumos-1, an autoregressive video generator that retains the LLM architecture with minimal architectural modifications. To inject spatiotemporal correlations in LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its imbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE scheme that preserves the original textual RoPE while providing comprehensive frequency spectra and scaled 3D positions for modeling multimodal spatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy that obeys intra-frame bidirectionality and inter-frame temporal causality. Based on this dependency strategy, we identify the issue of frame-wise loss imbalance caused by spatial information redundancy and solve it by proposing Autoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal tube masking during training with a compatible inference-time masking policy to avoid quality degradation. By using memory-efficient training techniques, we pre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on GenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code and models are available at https://github.com/alibaba-damo-academy/Lumos.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08800v1" target="_blank">NeuralOS: Towards Simulating Operating Systems via Neural Generative Models</a></h3>
                <p><strong>Authors:</strong> Luke Rivard, Sun Sun, Hongyu Guo, Wenhu Chen, Yuntian Deng</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.CV, cs.AI, cs.CL, cs.HC, cs.LG</p>
                <p><strong>Summary:</strong> We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08799v1" target="_blank">KV Cache Steering for Inducing Reasoning in Small Language Models</a></h3>
                <p><strong>Authors:</strong> Max Belitsky, Dawid J. Kopiczko, Michael Dorkenwald, M. Jehanzeb Mirza, Cees G. M. Snoek, Yuki M. Asano</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.CL, cs.AI</p>
                <p><strong>Summary:</strong> We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach leverages GPT-4o-generated reasoning traces to construct steering vectors that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of hyperparameter stability, inference-time efficiency, and ease of integration, making it a more robust and practical solution for controlled generation.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08797v1" target="_blank">Multi-frequency analysis of the ALMA and VLA high resolution continuum observations of the substructured disc around CI Tau. Preference for sub-mm-sized low-porosity amorphous carbonaceous grains</a></h3>
                <p><strong>Authors:</strong> Francesco Zagaria, Stefano Facchini, Pietro Curone, Jonathan P. Williams, Cathie J. Clarke, Álvaro Ribas, Marco Tazzari, Enrique Macías, Richard A. Booth, Giovanni P. Rosotti, Leonardo Testi</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> astro-ph.EP, astro-ph.SR</p>
                <p><strong>Summary:</strong> (Abridged) We present high angular resolution and sensitivity ALMA 3.1 mm and VLA 9.1 mm observations of the disc around CI Tau. These new data were combined with similar-resolution archival ALMA 0.9 and 1.3 mm observations and new and archival VLA 7.1 mm, 2.0, 3.0, and 6.0 cm photometry to study the properties of dust in this system. At wavelengths <3.1 mm, CI Tau's continuum emission is very extended and highly substructured (with three gaps, four rings, and two additional gap-ring pairs identified by non-parametric visibility modelling). Instead, the VLA 9.1 mm data are dominated by a bright central component, only partially (< 50%) due to dust emission, surrounded by a marginally detected, faint, and smooth halo. We fitted the ALMA and VLA 9.1 mm data together, adopting a physical model that accounts for the effects of dust absorption and scattering. For our fiducial dust composition ("Ricci" opacities), we retrieved a flat maximum grain size distribution across the disc radius of $(7.1\pm0.8)\times10^{-2}$ cm, that we tentatively attributed to fragmentation of fragile dust or bouncing. We tested, for the first time, the dependence of our results on the adopted dust composition model to assess which mixture can best reproduce the observations. We found that the "Ricci" opacities work better than the traditionally adopted "DSHARP" ones, while graphite-rich mixtures perform significantly worse. We also show that, for our fiducial composition, the data prefer low-porosity (< 70%) grains, in contrast with claims of highly porous aggregates in younger sources, which we tentatively justified by time-dependent compaction. Our results are in line with constraints from disc population synthesis models and naturally arise from CI Tau's peculiar spectral behaviour, making this disc an ideal target for deeper cm-wavelength and dust polarisation follow-ups.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08796v1" target="_blank">Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists</a></h3>
                <p><strong>Authors:</strong> Owen Lewis, Neil Ghani, Andrew Dudzik, Christos Perivolaropoulos, Razvan Pascanu, Petar Veličković</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.PL, cs.LG</p>
                <p><strong>Summary:</strong> What should a function that extrapolates beyond known input/output examples look like? This is a tricky question to answer in general, as any function matching the outputs on those examples can in principle be a correct extrapolant. We argue that a "good" extrapolant should follow certain kinds of rules, and here we study a particularly appealing criterion for rule-following in list functions: that the function should behave predictably even when certain elements are removed. In functional programming, a standard way to express such removal operations is by using a filter function. Accordingly, our paper introduces a new semantic class of functions -- the filter equivariant functions. We show that this class contains interesting examples, prove some basic theorems about it, and relate it to the well-known class of map equivariant functions. We also present a geometric account of filter equivariants, showing how they correspond naturally to certain simplicial structures. Our highlight result is the amalgamation algorithm, which constructs any filter-equivariant function's output by first studying how it behaves on sublists of the input, in a way that extrapolates perfectly.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08794v1" target="_blank">One Token to Fool LLM-as-a-Judge</a></h3>
                <p><strong>Authors:</strong> Yulai Zhao, Haolin Liu, Dian Yu, S. Y. Kung, Haitao Mi, Dong Yu</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.LG, cs.CL</p>
                <p><strong>Summary:</strong> Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are increasingly adopted in reinforcement learning with verifiable rewards (RLVR). They are often preferred over rigid rule-based metrics, especially for complex reasoning tasks involving free-form outputs. In this paradigm, an LLM is typically prompted to compare a candidate answer against a ground-truth reference and assign a binary reward indicating correctness. Despite the seeming simplicity of this comparison task, we find that generative reward models exhibit surprising vulnerabilities to superficial manipulations: non-word symbols (e.g., ":" or ".") or reasoning openers like "Thought process:" and "Let's solve this problem step by step." can often lead to false positive rewards. We demonstrate that this weakness is widespread across LLMs, datasets, and prompt formats, posing a serious threat for core algorithmic paradigms that rely on generative reward models, such as rejection sampling, preference optimization, and RLVR. To mitigate this issue, we introduce a simple yet effective data augmentation strategy and train a new generative reward model with substantially improved robustness. Our findings highlight the urgent need for more reliable LLM-based evaluation methods. We release our robust, general-domain reward model and its synthetic training data at https://huggingface.co/sarosavo/Master-RM and https://huggingface.co/datasets/sarosavo/Master-RM.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08793v1" target="_blank">Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning</a></h3>
                <p><strong>Authors:</strong> James McCarthy, Radu Marinescu, Elizabeth Daly, Ivana Dusparic</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> cs.LG, cs.AI</p>
                <p><strong>Summary:</strong> Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies that minimise the likelihood of rare and catastrophic constraint violations caused by an environment's inherent randomness. In general, risk-aversion leads to conservative exploration of the environment which typically results in converging to sub-optimal policies that fail to adequately maximise reward or, in some cases, fail to achieve the goal. In this paper, we propose an exploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic (ORAC), which constructs an exploratory policy by maximising a local upper confidence bound of the state-action reward value function whilst minimising a local lower confidence bound of the risk-averse state-action cost value function. Specifically, at each step, the weighting assigned to the cost value is increased or decreased if it exceeds or falls below the safety constraint value. This way the policy is encouraged to explore uncertain regions of the environment to discover high reward states whilst still satisfying the safety constraints. Our experimental results demonstrate that the ORAC approach prevents convergence to sub-optimal policies and improves significantly the reward-cost trade-off in various continuous control tasks such as Safety-Gymnasium and a complex building energy management environment CityLearn.</p>
            </div>
        
            <div class="paper">
                <h3><a href="http://arxiv.org/abs/2507.08792v1" target="_blank">The Effective Field Theory of Large Scale Structure for Mixed Dark Matter Scenarios</a></h3>
                <p><strong>Authors:</strong> Francesco Verdiani, Emanuele Castorina, Ennio Salvioni, Emiliano Sefusatti</p>
                <p><strong>Published:</strong> 7/11/2025</p>
                <p><strong>Categories:</strong> astro-ph.CO, hep-ph</p>
                <p><strong>Summary:</strong> We initiate a systematic study of the perturbative nonlinear dynamics of cosmological fluctuations in dark sectors comprising a fraction of non-cold dark matter, for example ultra-light axions or light thermal relics. These mixed dark matter scenarios exhibit suppressed growth of perturbations below a characteristic, cosmologically relevant, scale associated with the microscopic nature of the non-cold species. As a consequence, the scale-free nonlinear solutions developed for pure cold dark matter and for massive neutrinos do not, in general, apply. We thus extend the Effective Field Theory of Large Scale Structure to model the coupled fluctuations of the cold and non-cold dark matter components, describing the latter as a perfect fluid with finite sound speed at linear level. We provide new analytical solutions wherever possible and devise an accurate and computationally tractable prescription for the evaluation of the one-loop galaxy power spectrum, which can be applied to probe mixed dark matter scenarios with current and upcoming galaxy survey data. As a first application of this framework, we derive updated constraints on the energy density in ultra-light axions using a combination of Planck and BOSS data. Our refined theoretical modeling leads to somewhat weaker bounds compared to previous analyses.</p>
            </div>
        
        
        <div class="meta">
            <p><em>Generated by AI News Agent</em></p>
        </div>
    </div>
</body>
</html>